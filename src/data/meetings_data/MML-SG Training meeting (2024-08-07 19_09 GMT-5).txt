sí, todas las grabaciones que hemos hecho la idea, sería se pasa una transcripción y se Se entrena un modelo lm para que utilice sus datos Y tú le puedas hacer preguntas y él te tire las respuestas con base a todo lo que hemos hecho la primera versión va a ser solo con las grabaciones, pero adicionalmente se buscaría que fuera con código Incluso como en qué parte encuentro esta parte del código del autor que hace este este, pues que esperar que el performance sea lo suficientemente bueno, para que te diga mira en esta parte del código o en este repositorio ta ta pues como para ver cómo funciona el él sabe Mucho del tema entre gokul, framework, inicial es muy fácil de entender, me lo explico muy bien y con base a eso estamos construyendo eso entonces Esas dos noticias de entrada ahora por fin, por fin estamos llegando ya al final de de Cars que es todo lo que hemos utilizado para poder con un problema real encontrar carros baratos Ese es nuestro objetivo encontrar estos carros que son baratos en el
Utilizando Machine learning, lo logramos a través de algo llamado autoencoders, que es un modelo, no supervisado no se puede decir un poco auto supervisado, eh? Que se entrena con los datos Y a partir de los datos encontramos anomalías y las anomalías que queremos encontrar son precios baratos habrán más anomalías como precios más caros o kilometraje más alto o cosas parecidas, pero nosotros nos centramos en anomalías de precio arte ya después uno pueda con la demás Entonces vamos a a ver un poco de qué se trata para entrar otra vez en contexto. Entonces habíamos entrado en la tarea de autores, quería un poco expandir expandir, eh? Lo que se puede hacer el el uso más común que se tiene van a verlo con muchas imágenes se usa con muchas imágenes para reconstrucción de las imágenes
Los patrones base que es lo que estamos haciendo básicamente con los carros y me parece muy interesante porque encontré casos en los que se utiliza como para cosas de respiración cosas de pulmones cosas médicas que si encuentras algún número malía rara en algo en un comportamiento Incluso se puede aplicar en secuencias esa detección de anomalías, pues puedes tú, eh? Hacer cosas muy chéveres con imágenes las imágenes no son el tema más fuerte que de manejo la verdad pero que hay para hacer hay para hacer entonces me parece muy interesante ver esto y la otra me pareció interesante fue ver esta que era como con el cerebro imagino que también ya te puede permitir a ti encontrar cosas raras que no deberían estar ahí como en en algún órgano en algún cerebro con un auto incorrecto es encontrando estos patrones base y ahí mucha documentación al respecto miren Aquí está el ejercicio de los de los números que ya conocíamos que es el más común pero para que vea que hay mucha aplicación voy a irme un poco al pasado en una sesión anterior.
Nosotros habíamos visto Este vídeo que representaba un poco también, cómo funcionaba un Spears autoin Corner Pero hay una forma de hacer el esfuerzo Confort que es en vez de comprimirlo Y pasarlo por un cuello de botella, lo que hago es expandir este este espacio en medio y puedo separar conceptos, eh? Están relacionados dentro de los datos, por ejemplo, una neurona en este caso la neurona tiene compartida toda la información que tiene que ver con el sol con España que es posiblemente ya vamos como a Barcelona perritos, playa ballenas, Barcelona entonces es posible hacer algo así como una expansión y básicamente de eso se trata el el esfuerzo temporal que es sin Mostrar la animación es exactamente. Eso es creo. Se paró los conceptos los patrones base por cada una de las neuronas y de esa manera puedo entregarle un poco de explicación al modelo de
Cómo funciona ya puedo darle, eh? Puedo ya no es una caja negra, si no puedo expandir expandir perdón, eh? O separar estos conceptos y con base a esos conceptos, pues eh? Saber que cuando se activa de pronto, qué sé, yo la palmerita con el corazón, ya sabemos que esas son como las dos más predominantes para dar concepto específico, eh, Y una aplicación que me pareció muy interesante que lo están usando fue aquí. Esto es una página de opening explicando cómo van a ser o o Cómo extraer los conceptos de sajib Y cuatro Y ahí viene que están usando Spears entonces me pareció Genial que que para este tipo de cosas funcional aquí una un resumen sencillo, cómo funciona. Pues eh? That's Never activision. Se muestra cómo se está activando cómo está funcionando el orden neuronal y a partir del esfuerzo, puedo encontrar de nuevo.
Qué cosas son las que son predominantes los patrones predominantes por separado que pueden darles explicación a me imagino una secuencia de texto y demás me pareció muy genial haber encontrado esto porque pues miren cada rato va saliendo como como, eh, En junio, estos bastante nuevo, eh? Va saliendo como aplicaciones muy interesantes de lo que se puede hacer con justamente lo que estamos aprendiendo en este momento y que hoy vamos a ver, ya detalle Cómo rayos. Funciona Cómo se pueden hacer este tipo de modelos y en este caso para un detección de anomalías, pero que sepan que hay mucho más que hacer y es un tema actual, no estamos viendo algo, que pues no regresó lineal, no, nada Esto está pasando en este momento y la están usando las compañías, pues más grandes en diferentes áreas eso me pareció genial para que lo veamos Entonces ahora sí, entramos como el concepto de Spears recorder, eh? Que es básicamente una variante del auto.
Que lo que hace es agregar un factor de regularización, básicamente factor de regularización se usa, eh? En el entrenamiento de redes neuronales para evitar que tenga overfield es básicamente el principal objetivo o al fin Recuerden que es cuando hay sobre ajuste y el ejemplo del carro cuando aprendes a manejar exactamente un carro, pero cuando te tiran un carro diferente con diferente pequeñas variaciones, pues empiezas a hacerlo muy mal porque estás acostumbrado o muy sobre entrenado con un carro, específicamente se utiliza principalmente para eso en este caso se se agrega un factor de de regularización en el auting corner Con un objetivo diferente que sería separar estos conceptos o hacer que cada una de las neuronas se enfoque en una característica específica del de del conjunto de datos. Entonces voy a colocarlo de pronto un poco.
Burto en un ejemplo pero para que se entienda un poco tenemos las imágenes que es como pintó el número dos cierto y quizás hay una neurona que se enfoca en esta línea diagonal pero que también de pronto esa se activa cuando tiró el 7 porque el dos va así y el 7 también sabemos que es como así entonces ese patrón es el que el que está dedicado a una sola neuro en vez de que todas las neuronas funcionen como en un mapeo de identidad sería la palabra que tiró la entrada a todas trabajan como en conjunto y me sacan la salida, eh? En este caso por eso que una que una de las neuronas se enfoque en uno de los patrones base de ese conjunto de datos entonces presionando ahora una función para esta otra para los las líneas que están así otra para las líneas que están arriba Entonces de esa manera esfuerzo que haya una distribución digamos del conocimiento por neurona sería un poco la explicación la forma en la que
Se hace de nuevo factor de regularización, hay diferentes factores de regularización que vamos a ver ahorita que se explicaría cómo funciona, pero el efecto sería este básicamente en el espacio latente es el cuello de botella, las neuronas que están allí van a ser entrenadas para que cada una se especialice en un patrón Esto me recordaba un poco Cómo se entendía como poco como un pca como si cada una de las neuronas se entendiera uno de los ejes, uno de los de los de los de los ejes que se utiliza para hacer el psa, por ejemplo algo así se me venía la cabeza un poco, eh? Pero que se entienda que va por ahí. Entonces, eh, Cómo se hace, pues este factor de regularización hay varios, hay varias formas de hacerlo Espera a ver si me estoy perdiendo algún cambio está como debería estar listo Hay una que se llama.
Entonces miremos como las técnicas de regularización que hay en redes neuronales, hay dudas que funcionan para otros algoritmos que puede ser, por ejemplo, el l1 o el L2 hay otras que funcionan para solo la red neuronales, que es por ejemplo un Drop out, que se la vamos a ver esta página me encanta, pero la odio porque tiene muy buena información, pero siempre pide que te lo que es, es horrible de la casa de la explicación. Básicamente que se busca que no tenga Uber eh, que sea como el el objetivo el objetivo de la red normal y por aquí deberían estar hablando de l1, L2 que son básicamente, eh? Los nombres no, que no los asuste son nombres que se le ponen a cuando yo aplico la regresión o perdón, el el entrenamiento y hago el background a s.
Por de error que es como compárame la entrada la salida que generaste con la real con el target en este caso con párame la imagen de entrada que te estoy tirando con la imagen que me generas Y a partir de ahí voy calculando el error. Le agregó un factor de castigo que se podría llamar así un factor adicional de castigo que dependa en este caso l1 L2 que dependa de los pesos del arrendar Entonces les comentaba la vez pasada que cuando Se entrena una recta normal, cada uno de los pesos son como estas conexiones entre neuronas cierto y el problema es que esos valores podrían haberse ser muy grandes y muy variados. Uno podría estar en 300 otro en 500 otro en dos o tres 20 estados Entonces cuando se tienen números tan variados en esas conexiones, digamos de la red neuronal, hay mucha inestabilidad Se podría decir desde ahí también estabilidad porque podría ser muy sensible al ruido muy sensible a diferentes cambios que por estos.
multiplicadores que se usan puede ser un poco inestable para evitar eso se agrega un ese error ese factor de error depende de los pesos entonces como yo quiero minimizar este error que depende de la resta que yo hago o el el criterio que puede ser un MC mini Square Recuerden que es esta forma en la que Yo calculo el error entre la salida que me genera y el target real pero eleva al cuadrado Ya vimos porque podía ser útiles en esos casos con otros bueno se utiliza ese factor pero adicionalmente le agrega un factor que dependa de los pesos entonces eso qué fuerza que la red neuronal tenga que aprender a generar la salida en este caso la incorre y al tiempo que los pesos que se usan que son estas conexiones entre las neuronas sean pequeños también los más pequeños posibles básicamente la diferencia entre l1 L2
L1, lo que hace es minimizar lo más posible los que no son relevantes los pesos los conexiones que no son relevantes mientras L2 literalmente las vuelve a hacer, o sea es como si hubiera conexiones que fueran 0 O algo parecido o que o que en el aprendizaje que se hace se borrara los factores que no son relevantes o los patrones que no son relevantes en ese conjunto de datos Y se borraron uno lo minimiza otro lo borré eso es como la la gran diferencia y la fórmula matemática vaca que uno deseado al cuadrado El otro es como el valor absoluto y ya con un poco de lectura se entenderá pero básicamente se la gira un factor de castigo es una forma de hacer recolonización el Drop out que era el que les comentaba que solo funciona para redes neuronales Este es otro método de regularización que lo que hace es básicamente Apagar y prender algunas neuronas, eh? Lo que yo hago es de una forma Random apagó y prendo apagó y prendo Y eso, qué fuerza que la red neu.
Tenía que distribuir entre comillas el conocimiento en todas las neuronas porque tiene que entregar un resultado igual de bien con con las neuronas que con las que se está entrenando en este momento si se dan cuenta, él tendría que generar, por ejemplo aquí el precio, porque esto no es un dato en tendría que sacar el precio, eh? Solamente con las neuronas que están activas, es decir con los pesos que se tienen entonces tiene que de alguna manera distribuir este conocimiento entre todas para que siempre tenga un un buen resultado a la salida y y ese tipo de efectos son los que vemos acá en Drop y hay otra que funciona muy bien De hecho no está aquí, pero es la que estamos utilizando en este momento para entrenar nuestro modelo que es una que se llama Hills que eso ya lo hemos visto también en la sesión anterior y era básicamente como queremos generalizar un poco más con el open curry porque Qué pasa de lo que ocurre.
Cuando está aprendiendo con valores discretos que es sin hacerle ninguna modificación tal cual le tiró la entrada pasas por el cuello de botella, metemos la salud lo que pasa en el espacio latente que son las la información que están en las neuronas del cuello de botella. Es que llegan a ver algunos Campos vacíos, Como algunos huecos, Como algunos, eh? Espacios que cuando no tienen suficientes datos se generan vacíos Entonces eso también lo hemos visto un poco en la en la sesión anterior, que esta imagen nos ayudó un poco a entender, cómo funcionaba la imagen está por aquí seleccionar Esta sí que es, básicamente es como si quisiéramos lograr que el espacio latente no fuera solamente puntos sino que ahora funcionará como distribución como
Si pudiera yo expandir, expandir la información de esa instancia Y que cuando tengo varias instancias pegadas, pues se comparte esa información y de esa manera, pues voy llenando como Esos huequitos, sí, entonces la forma en la que logramos eso es con aplicando este factor de regularización que se llama aquí el divergens que básicamente lo que hace es comparar dos distribuciones acá la imagen se entiende bastante una distribución del azul. La otra distribución es la la verde entre más se parezcan, por ejemplo, ahí es cuando menos tengo el error que sí sean cuentas cuando tengo la Las barritas más abajo, Sí cuando ahí él intenta parecerse a una, pero la otra está muy alta significa Pues que va a tener mucho error para uno pero para la otra pues va a estar muy quedada entonces ahí, eh? Es el método que estamos utilizando para poder activar está regularización lo
Aquí es donde les decía que tenía como ese hueco que todavía me falta como llenar la verdad es que le le ha dado tuve una conversación larga con chachi, pipí leí papers y demás Pero me falta aquí está la conversación larga larguísima y para entender esto pero básicamente cuando le agregas ese factor de de regularización en ese cuello de botella en el espacio latente logras que cada una de las neuronas Recuerden que lo que queremos es que cada una de las neuronas se se especialice en una característica base de ese conjunto de datos, entonces logras que cada una de esas neuronas se especialice la pregunta, sería Cómo Ahí es donde tengo el básico o sea cómo funciona como para yo decirles una analogía Así que que creo que ha servido para explicar temas complejos. Ahí tengo el vacío Cómo aplicando este error de factorización de de regularización genera esa distribución me falta. Me falta según entiendo, es un poco con
No se llama speiser de que de ahí viene el Spears buscas que se activen o no algunas neuronas en cierto tiempo muy parecido al Drop out, pero no es como el Drop out, ahí me falta $100. Son estos que operan con ustedes. Me falta estudiarlo más la próxima. Espero que ya esté resuelta la duda. Si alguno también la llegas a ver, porfa, la comparte porque el espacio también lo tengo en la caja, me serviría mucho, pero que entiendan que con un factor de regularización se logra ese efecto en la que cada neuronas especializa en una característica Y ahora, qué pasa cuando ya le tiras una entrada le dan una salida, pues estás neuronas funcionan en conjunto, pero ahora es como si cada una mafia cada uno de los ejes de ese conjunto de datos, o sea, como si ponle tú va a colocar aquí una distribución cualquiera mostramos un 3 de distribución que es es la forma en la que yo le entendí.
Que me ha funcionado. Creo que está nos va a servir bastante bien o más bien está me parece más chévere es como si como si cada una de las neuronas fuera la que mapea cada uno de los ejes, sí Entonces tenemos una que está acá en este eje tenemos otra neurona que solo se especializa en este eje y las dos jugando en conjunto, pueden llegar a mapear todo el espacio Sí porque dependiendo de las entradas, pues como unas especialistas no características de los otros la otra, pues ambas van moviéndose en conjunto, para generar esas salidas a Y de esa manera, pues podemos tener esa distribución en el espacio latente en vez de tener puntos discretos, ese ahí sería la meta que ya no es un punto discreto, sino funciona como en conjunto, una distribución mapeando una distribución Así que es lo que se ve Entonces ahora sí, echémosle un un una revisada al código veamos, qué rayos Bueno aquí está la regulaciones. Son importantes Ya lo vamos a ver.
Un poco y esto Aquí vamos, que no se me escapa nada ahorita listo se vuelve un poco de rojo el código veamos cómo las diferencias que tiene, eh? Lo que acabamos de de construir respecto al al autor bien. Entonces cosas nuevas que en el en el proyecto van a encontrar en la carpeta de Test y the train las minimizo, porque así no puedo ver tiempo Perfecto entonces van a encontrar dos el primero es un train normal, que es el que teníamos nosotros para hacer el Trade del autor normalito sin cambios y el otro es el Trade para el space, ya vamos a ver por qué hay diferencias listo, entonces, eh, Para hacer un un recado como memoria de lo que de lo que habíamos visto hace un momento.
De la sesión pasada de autor Entonces tenemos el conjunto de datos que es el que entra que es el de carros, leemos como si es bit definimos Cuáles son cuál es la dimensión de features que hay porque eso es lo que va a recibir nuestro Twitter de entrada, entonces ahí simplemente calculamos, eh? Transformamos eso en un tensor que es, básicamente lo que sea así aquí y lo que se hace aquí esto Qué sucede acá es solamente algunos argumentos de hecho esto debería estar más arriba, lo voy a mover esto debería estar aquí al principio, básicamente son variaciones de argumentos atrás, no no es mucho más acá se transforma en un tensor porque estamos usando python y python se utiliza esta transformación de tenso para que sea más eficiente en el cpu o en el gpu según lo que usó entonces acá hacemos el Script del del trading y el validador es con el que el validado Recuerde que es el que usamos para que no haya overfield entonces, eh?
Entrenamos con el Trade validamos con el validador aquí, simplemente sacamos lo lo partimos básicamente Y tenemos los dos datos sets, están acá bien acá se utiliza lo de Patch que Recuerden que también le agregamos un poco de batch para que fuera más rápido el entrenamiento Porque si usamos el punto de datos completos se demoraba mucho más entonces era lo que hacemos en la sesión anterior como la analogía es como si fueras un poco borracho Pero todavía vas en la dirección correcta cuando calculas el error entonces Si usas, todo el conjunto de datos usas muchas cpu mucha seguridad te vas a demorar mucho más. Entonces acá cuando llegas como este batch o es como información Random que te puede decir en qué dirección tomar Cuando haces el el cálculo del gradiente y bajar el error, básicamente utilizamos esta función que es la que se utiliza cuando obtuvo que la hemos visto que es un optimizador aquí lo hacemos Eh para poder.
Perdón no te invito a ver no, sino como fine Junior es el que es utilizar para poder encontrar el hiper parámetro del raid para poder encontrar, Pues el el mejor valor para poder tener el el menor error en la reconstrucción, Porque necesitamos iterar con varias cosas oportuna, te hace eso automáticamente incluso él va definiendo Cuáles son las mejores opciones de esos hiper parámetros para que funcione mejor utilizando métodos de probabilidad como Valles o algo así hay en la documentación de lo que uno aparece Pero esto te lo simplifica por cada uno lo dice coach, pues hacemos como el entrenamiento aquí el trading calculamos el error, si se dan cuenta el error es normal el error que aparece acá el que vamos acá es del criterio el criterio es el MC es básicamente compare entrada con la generada y saca el cuadrado. Eso es lo que estamos haciendo acá. Básicamente se puede utilizar otro pero este es bastante bueno para los atentos hacemos la parte de validación que es la que está acá.
Simplemente para imprimir cuánto fue el error por el batch y por aquí abajo, a ver esto era para mirar Cuánto se demoraba que eso también lo vimos la sesión anterior, si le metes más barach O si le metes como este sampling que también tenemos utilizando colmo de Office smirno, pues bajar el el tiempo de ejecución y acá el leer listo es básicamente si ya estás embarrando la validación, pues para no quiero que la sigas en barra, sino que estamos diciendo ahí, eh? Aquí está la tuna. Queremos minimizar el error que nos retorna que es el error de reconstrucción, que ya sabemos que es como el error que Calcula con el de validación y hasta ahí, eh? Lo tiramos funciona bien, no había aquí la siguiente parte era coger ya los mejores hiper parámetros y volver a entrenar, pero ya con los mejores hiper parámetros que todo esto básicamente es una copia de lo que hay arriba.
Pero ya con los mejores hiper parámetros no tenemos que hacer pymes, sino ya entrenamos como la versión del modelo. Final, eh? Tenemos la última versión generamos pues todas las salidas el diccionario de información de error de reconstrucción para saber que también lo había hecho y demás guardamos el modelo y hasta ahí ya ese era el base que teníamos nosotros cierto Quizás otra cosa adicional, que vamos a ver acá es Déjame sacó el autor el autor es la muy sencillo, tenemos, eh? El encoder que va, eh? Con con estas funciones de activación, ahí hacemos el como el embudo, si se dan cuenta va bajando de 84 54 hasta 40 y es de 40 reconstruye otra vez al final teníamos un timer Porque queríamos que estuviera en un Rango de 0 y 1 porque el error de reconstrucción o la reconstrucción dado la normalización.
Qué hacíamos al principio los datos? Vienen normalizados están en un Rango de 0 y 1 queremos que nuestras salidas estén en un Rango de servidor, entonces básicamente eso se hace y aquí el Forward conecta esas dos partes sencillo y ahí ya con eso teníamos ahora diferencias. Empecemos de pronto con con el modelo con el Spears Cómo se vería un space of rencor que funcionará con divergens con este factor de regularización para que creemos esta generalización Yo sé que esto De pronto es un poco más denso si tienen dudas de una levanta en la mano o abren el micrófono todavía no hay problema. Igual les dejo libros y todo me preguntan listo. Entonces aquí hay un factor adicional que se agrega que es raw, que ya lo vamos a ver básicamente me dice Con qué con qué frecuencia quiero que se desactiven estas neuronas.
En el espacio latente para que genere ese ese espíritu Esa esa especialización de neuronas por cada uno de los filtros Con qué frecuencia básicamente eso es lo que se podría resolver también es un hiper parámetro. Eso es lo que lo que se ve allí, eh? Tenemos el el el Encore el autor. Si se dan cuenta aquí funciona con simmon la razón por la que funciona con Simón es porque ahora estaríamos trabajando con distribuciones y queremos acotar esas distribuciones dentro de un Rango de servicio, esa es la razón técnica de porque aquí en medio se usa Simon y aquí se usa red la xr de hecho es porque en este caso yo no a mí no me interesa mucho, si si en realidad supera el uno o va Incluso el negativo no me interesa si siempre me reconstruya bien en este caso, como estamos trabajando con distribuciones. Queremos que esa distribución digámoslo así se parezca como una instrucción un poco gau.
Normal, que sea que se acote en un en un espacio controlado, esa sería la razón técnica por la que aquí se usa Side vale, al final también se usa Porque queremos que esté en este en este Rango también Aquí hay una diferencia que ya vamos a ver cómo se utiliza el power. Voy a colocarlo aquí de pronto una al lado del otro que será más fácil leerlo así yo no sé si ahí ven mi pantalla necesitan que la Grande un poco más o ahí se estoy seguro silencio estoy bueno, ahora sí, eh? Entonces si se dan cuenta acá el Forward qué pasa en Forward la entrada que es x pasa a través del encoder es lo que está definido aquí arriba a través de ese cuello de botella, el resultado que sería básicamente este x este x se podría.
presentar acá como espacio latente late en x este sería como el espacio la la parte que está en la mitad de los datos que están en la mitad Sí para que se entienda un poco Y a partir de ese espacio latente que tengo ahí paso por el licor y me entrega como el X reconstruir este sería como reconstructor algo así y esto es lo que me retó Sí así es como la conexión en este caso en el Spears Open Corner funcionaba un poco diferente se separa y se retorna el espacio latente y se retorna la salida es decir se reto en la información cuando ya pasó por el encoder que es cuando ya pasa por el espacio latente y se retorna el de cobre que es cuando ya pasa por el decoro ya vamos a ver porque porque se se hace de esa manera si se dan cuenta acá ya retorna son estos dos datos Y aquí solo retorna uno
Nos trae Sí ya vamos a ver cómo funciona y Cuál es la diferencia algo adicional que tiene este este modelo es que tenemos ese Este esta función que nos nos calcula la divergencia el y el dygert en el cual le vamos a tirar, eh? Déjame lo pinto por acá listo Le vamos a tirar la información que se reconstruyó y es aquí el dirgen Aquí discúlpenme también, que tengo el hueco mental todavía no sé a profundidad, cómo explicar cómo funciona. Entonces va un poco parafrasear de la forma en la que lo el que el diogen lo que te va a hacer es con ese espacio latente forzar que algunas se prendan y se apagan algunas neuronas y de esa manera hace que se distribuya como el conocimiento. Eso es lo que hace esta función acá y eso Por esa razón es que
Esta función que es el dos funciones que ya vamos a ver cómo se utiliza va a recibir la información que viene, eh? Eh, del Encore o sea una vez que está en el que pasa a la mitad sí Entonces cuando queda la mitad, eh, No sé si está siendo muy complicado El tema, lo llamo el resultado vamos a ver los resultados tenemos este los funcionarios que es el que va a reemplazar las funciones normal que tenemos en el criterio, ya vamos a ver también un entrenamiento de las diferencias Y acá es donde quería También mostrarles, tenemos el error el error que se calcula normal de la entrada de la salida, el de cobre que Recuerden que el licor es cuando ya pasa la salida cuando ya tengo la salida reconstruida Le sumo este error de eh? Perdón de lo cálculo con el error de la entrada miro, el cobre el auto en correr normal está el mca y los
Pero le agregó el error adicional que voy a calcular poner aquí el dior el factor de normalización y le meto un beta y un Beta es básicamente, qué tan qué tan importante vas a hacer? Qué tanto vas a afectar esa ese esa reconstrucción y esto también es un hiper para que va a estar en un Rango definido, qué tan qué tanto peso va a tener ese ese factor de de castigo que te va a poner para que la neurona tenga Pues un ese enfoque en un es especialista en un factor del conjunto de datos, Vale ahora vamos a echarle un poco al Script de entrenamiento. Nos va a poner también un al uno al lado del otro y veremos algunas diferencias, entonces Disculpen esto no va esto ahorita lo estaba probando para usar la gpu. Ya voy a mover esto también para aquí arriba Estos son las validaciones de los argumentos. Esto sería esto por acá listo.
Perfecto, la parte inicial, igual separamos el Data set validación training Exactamente igual y por aquí es donde empieza a hacer un poco diferente en el oxx solamente tendríamos el landing rate para poder Encontrar el mejor valor del refri, rate para entrenamiento auditorio, Sí aquí le vamos a agregar dos más uno que es Beta que es este factor que me dice qué tan importante es el Kia o el error de Kill el tan importante es esa diferencia En distribución ese error y el rock, el ro básicamente me va a decir a mí, eh? Espera que es solo pasé aquí por alto discúlpenme que eso está aquí y ese error se usa Ah okay, el ro es un eh? Es un factor que se usa en en el Kill diben también es un hiper parámetro para calcular aquí es lo que te hice.
Con qué frecuencia va a estar prendido o apagado cada una de las neuronas Con qué frecuencia se apagó se prende cuando los demonios para que tenga ese esa que se fuerza que cada uno tenga una responsabilidad entonces también es un hiper parámetro entonces este es el peso que le voy a ese error de divergencia este es que tanto quiero que se apague o se apaguen nuestras neuronas en el centro del espacio laboral entonces reconstruyó, eh? El modelo Aquí mandándole el rock como argumento de entrada porque así está diseñado en el constructor el optimizador igual el stopping también igual y aquí está la diferencia de cómo ya se calcularía como ese error en vez de utilizar acá el criterio de hecho vean que acá se usa criterio en el normal para calcular el error era básicamente comparo la entrada por lo que me genera el orden correcto.
Comparo Y a partir de ahí cálculo, error en vez de hacerlo, así que es la forma normal, lo hago pues con la función que nosotros especializamos en el modelo que básicamente sería esta de acá que va a tener ese error normal que hemos manejado, pero le agregamos este factor de de castigo de regularización con el cuidado, eh? Digo chicos, básicamente con esa divergencia entre las distribuciones que Recuerden que ahí todavía tengo un hueco. Estoy ahí estaba trabajando en eso para Ojalá explicárselo en la próxima sesión, entonces este error ya sabemos que viene alimentado de eso de esos factores aquí la predicción Recuerden que ahora la predicción cuando yo la hago El Forward es decir, cuando aplico el módem acá se ejecuta esta función llamada forever es básicamente predica, eso es lo que estamos diciendo ahí cuando predice él me va a entregar, pues la información de la encode y la información del Deco Y a partir de ese código.
Es lo que nosotros utilizamos para calcular el error, porque eh, también estaba leyendo un poco Por qué razón aquí algo que uno ve en el código es venga, por qué se calcula el error de esta divergencia del Kia en el espacio latente y no en la salida sí, por estas razones que se parte porque un error se calcula en el espacio latente y otro error, se calcula en la salida y el argumento era que porque en el espacio latente es donde yo quiero forzar que haya esa, eh? Ese esparcimiento del conocimiento o esa especialización por neurona porque quiero que ahí suceda Entonces al Añadir estos dos errores, lo que hago es que como quiero minimizarlo lo que hago es que esfuerzo que todos los pesos con los que se Se entrena el el auto en Core logren ambas cosas tanto reconstruir bien Cómo lograr que cada una de las neuronas tenga una responsabilidad y que funciona así como les decía ya como una distribución como un mapeo completo.
Entonces, por eso es que funciona ligeramente diferente acá retorna, dos valores y esos dos valores son los que yo uso, pues para alimentar y calcular ese ese error y ya con este error, pues yo hago báculo, que ya sabemos acá y es exactamente lo mismo lo mismo funciona para validar, Esa es la transformación que se hace ahora encuentro la reconstrucción en el centro y también encuentro la salida con ellos cálculo el error y hago que el modelo se entregue cumpliendo esas dos tareas tanto reconstruye bien como que las neuronas en el espacio latente tengan cada una una responsabilidad o que estén que encuentren un patrón base en ese punto y así es como funcionaría y ya el resto es igual, le tiras Pues el mismo esto solamente para calcular Cuánto se demora y aquí le tira, se lee stopping es para que lo haya golpeado la misma idea, eh? Mejores parámetros reconstruye igual.
Hago Aquí también, pues el cálculo del error de la manera que ya sabemos que debería funcionar para guía y ya Así es como lo tiró eso que me va a entregar a mí, pues un modelo que va a ser más robusto menos sensible a ruido, eh? Taba tapar esos huecos vacíos que encontramos en el en el espacio latente especialmente era lo que les comentaba, pues se genera solamente un punto ya esto funciona como si las neuronas funcionan en conjunto y plotear todas una una superficie, si lo vemos en un campo 3D eh, Es cómo funcionaría un poco la la vaina Y eso que nos entrega un detector de anomalías más robusto que nos va a entregar mejores resultados, listo chicos, hasta ahí dudas si algo después me pueden escribir, Yo sé que esta parte es la más densa, pero justo estos temas me parece Quién va a tratarlos y yo sé que hay dos chicos que se fueron.
No sé asustar, pero bueno, hasta ahí bien Laura dispara, Mira yo entendí el tema, pero me queda la duda, es que que entra al modelo y que sale, o sea, es que todavía no, no entiendo bien, va a salir. Hablamos la la lo dice una pregunta, creo que la clase de antepasada era al final el output va a ser si es una noma, lo no es anómalo O cuál va a ser el output del modelo O sea no, no me queda entonces solo que solo que tengas aquí en cuenta, quizás aquí sabes que me ayuda la presentación que yo hice hay una imagen que me sirve mucho en algún momento ya te comparto exactamente, a qué me refiero yo usé esta imagen en la presentación que hice que creo que yo bastante entender.
Eh, qué es lo que queremos encontrar que sería tener un autor que funciona para detectar números No todo lo que sea un número lo va a entender bien, lo va a reconstruir bien el error de reconstrucción, va a ser pequeño apenas le tiré algo que no sea un número porque él no se entre no con cosas que no sean números como una prenda esto es un vestido una camisa, digamos él va a intentar reconstruirlo, pero lo va a reconstruir horrible muy feo, sí Entonces esto es lo que haría un Note en Corea normal cuando el Spears of the Corner nosotros podemos lograr que el el módem encuentre los patrones base y que pueda generalizar mejor al reconstruir estas imágenes entonces podría haber otro dos que nunca haya visto con de pronto lo sé que sea más pegado a los bordes más grande y demás, pero como ya encontró los patrones base y ya no.
Anda como un modelo de copia de identidad Con qué me refiero a copia de identidad yo te tiro esto que me reconstruyen lo mismo, no, sino que ahora encuentras los patrones base con los que se reconstruyen esas imágenes o eso o s al encontrar los patrones base es más robusto a nuevas imágenes que vengan yo le podría tirar un dos que que sea lo que te digo pronto más gordo más pegado a los bordes, pero como encuentran los patrones básicos puede que me lo reconstruya Igual igual de bien, sí, a pesar de que ya tengo un poco diferencia es un poco más bruscas. Cuando nosotros ya calculamos el error de reconstrucción consideramos que hay una anomalía Sí ya supera un valor límite un trecho Sí pero en este caso. Nosotros vamos a hacer algo un poco diferente es por cada una de las características este error de reconstrucción se es la sumatoria de de cada uno de los de las características que tiene que tiene el
El el dato por ejemplo en en las casas o en los carros creo que las casas entienden más fácil porque los carros no los carros también funcionarios. Yo le tiró el modelo el modelo el tipo de modelo Me lo me lo reconstruyó bien. Yo le tiró la marca. La marca me lo reconstruyó ahí. Yo le tiró, eh? Kilometraje kilometraje me lo reconstruyó bien. Yo le tiró el precio el precio me lo reconstruyó mal o hay mucha diferencia porque el precio que debería tener ese ese carro da las condiciones que me tiraste Debería ser tanto, pero no no es tanto sino es, eh? Ahí es donde yo encuentro la oportunidad es mucho menor o es la mitad o es 30% por debajo? Porque yo estoy reconstruyendo entonces, eh? Cuando usas. El Spears autointer logras que sea Mac robusto incluso la solución más potente Eh no sea tan sensibilidad nuevos cambios o datos que tengan ciertas.
Sino que encuentra los patrones base y con esos me reconstruye el ven ya cuando tienes que es el el siguiente paso no sé si ahí respondo tu pregunta hasta el momento sí, ya claro Gracias listo. Entonces el truco que nos lo aplicamos aquí es el siguiente en la Gráfica como Uy la Gráfica como ustedes pueden ver el reconstruye pero suma al final suma todos y nosotros no queremos sumar en realidad en vez de sumar lo que nosotros queremos, es por cada uno de esos factores encuentro que tanto la embarraste Sí entonces en teoría para los mayoría la mayoría de casos, el error en todos Debería ser muy cercano a cero Sí porque Entonces debería reconstruir igual de bien. Entonces si yo le tiró la entrada, pues me debería tirar la salida muy parecida muy parecida y el error en realidad Debería ser muy parecido entonces cada uno de estos puntos que aparece acá.
Estar cercano Sí cada uno de estos x. Básicamente o está resta que hay acá x x 1 sombrerito menos x. La resta, Pues debería ser cercano a cero cercano a cero cercano, lo que haces ahora es por cada uno de los datos que le metiste coges la reconstrucción coges el error de reconstrucción, entonces tendrías una matriz que tiene todos los errores, es decir, una matriz que te dice En qué tanto la embarró por cada uno de los datos por cada una de las características de Seat es decir por todas las casas que yo le estoy tirando él me va a decir esa matriz. Me dice en la casa, uno la embarré en la habitación en la casa dos la embarré en talcos, Por qué se queda la embarré porque el valor no es cercano a cero, sino es uno o es -1, pero no es cercano a cero, Sí eso es lo que nosotros queremos hacer acá es básicamente por cada uno de los ejes, pues mirando que tanto las barras.
Entonces tienes este este esta matriz que tiene toda esta información con el error de reconstrucción hay un algoritmo que se llama keen que también es The Machine learning, es un algoritmo, no supervisado que es muy sencillo entender el Simplemente si lo podemos si lo podemos colocar en Jeff mejor siempre me gustan porque son como muy fáciles de entender a ver si sirve Ah este creo que sí es bastante. Bueno, casi creo que estés mejor lo que hace básicamente es te pones en una posición y básicamente le dices tráigame los cinco más cercanos los 10 más cercanos, los nyte más cercanos que tenga cerca su posición Entonces eso porque es relevante en el caso.
En el que nosotros lo aplicamos porque como tenemos todos estos errores de reconstrucción, nosotros aplicamos este algoritmo para decirle tráigame todos los datos en los que o todas las instancias en las que tú hayas reconstruido todo bien excepto el precio, ahí quiero que me traigas el dato que yo necesito Sí y se usa como tenemos todos estos errores de construcción, entonces todos los todos deberían estar muy cercanos a cero y a mí me interesa, son los que están en todo 0 menos en el precio y ahí es donde está la magia y yo le digo tráigame todos esos menos en el precio y ahí está la anomalía la anomalía deseada es decir con características, que a mí me sirven y ahí va, entonces es algo muy sencillo, pero en este contexto es muy útil muy muy útil, a ver si aparece con otro lado más chévere, sí, Mira esto como que lo explica bastante bien. Esta es la referencia. Entonces acá le estoy.
Llama a los tres uno le puede tirar por radio, hay diferentes formas, le puedes tirar por radio como lo está haciendo acá o lo puedes tirar por número entonces cuando ya cojan los primeros cuatro para y ya no me traiga más que es como el otro lo estamos utilizando nosotros lo estamos utilizando la Ah De hecho. Aquí está esta imagen esta imagen sirve mucho, le decimos. Tráigame los primeros cuatro, entonces acá va a coger estos azules, Mira el el verde es la referencia y los cuatro son los más cercanos. Ahora tráigame los nueve. Tengo los cuatro que están acá y estos cinco que están en rojo. Sí, tráiganme los siguientes 10, pues va a apenas toque alguno de estos que están en el borde, pues para que me traerá esa información tiene sentido Cómo funciona el último truco que ese ya usando la reconstrucción o hay dudas Está bien, voy a seguir entonces recuerde que si tienen dudas simplemente Levanta la mano o abre el micrófono Entonces tenemos esto este error de
Y lo que hacemos Es aplicar ese algoritmo que es lo que ya vamos a ver aquí aquí cree un un Script que se llama Ted inference, porque esto ya sería un poco más de parte de la inferencia, no del entrenamiento del modelo, sino ya Cómo se usa acá, que estamos haciendo para que se entienda Leo la información de Test que utilicé la misma información que utilicé para entrenar el modelo esto podría ser el test del Trade básicamente el conjunto de datos que tú quieres pasar por el autor para poder encontrar las anomalías. Esto podría ser, por ejemplo, los últimos carros de la semana podrían ser los últimos carros de la semana. Sí funciona Este es el es la misma información que aparece acá simplemente que es la original sin aplicar la transformación Por qué es la original porque si vemos esto con ese montón de columnas que tiene porque la aplicamos un poco un montón de transformaciones o Afore corín bla bla bla bla es dificilísimo leer a nosotros como humanos.
Es difícil, entonces ya vamos a ver que está, eh? Este dato set se utiliza ya es para entregar los resultados business de negocio. Cómo se verían desde negocio, eh? Le estamos diciendo tráiganme los primeros 10 los primeros 10, anómalos Esos son los que me interesa Y acá es donde está la magia. Estás Estás las referencias Este es el el la instancia de referencia, básicamente el punto verde que yo quiero que me traiga y cuáles son Quiero que en todas reconstruyan bien excepto en el precio que el precio está en la columna tres Sí en el precio quiero que me traigas las que la embarraron en el error, pero de forma negativa es decir, el error que sea más baratos de lo que deberían ser Entonces eso es lo que le estoy diciendo acá en el resto quiero que me que me que me me traigas todo bien, o sea, que los más cercanos en los que hayas reconstruyó todo bien excepto el precio, eso es lo que le estoy diciendo acá.
Entonces acá ya, eh, Leo la información como un Data frame, eh? Calculo el número de features. Esto es básicamente porque tocar transformar esto a tensor de hecho esta parte de net Future se podría mejorar. Esto es más de programación, pero se utiliza para inicializar Pues el modelo. El modelo lo cargamos con la información de del modelo, que ya sabemos que funciona es un archivo que tiene como todos los pesos de todas las de todas las neuronas y todas las conexiones porque ya lo entrenamos entonces aquí simplemente se inicializa y se carga, se puso se pone en modo evaluación. Esto lo hemos hablado también en sesiones anteriores. Si es Porque algunos modelos activan algunas neuronas solo en el entrenamiento, por ejemplo, el Drop out, solo funciona el entrenamiento entró Power es cuando apagó y prendo no apagó y prendo algunas neuronas, eh? Pero yo quiero que eso solo pase en el entrenamiento. Entonces, por eso se utiliza este Eva porque
Digo vea, usted va a utilizarse en modo evaluación no entrenamiento Entonces se utiliza este este método aquí, qué hacemos? Predecimos estos nos va a entregar el error de reconstrucción que es este acá es el decode de hecho incluso este dato de acá a mí no me interesaría. Lo podríamos colocar como raya al piso que es como un valor como un Sin nombre es una variable que tenemos ahí como Sin nombre. Eso se puede python, pero el que nos interesa es ético que ya la reconstrucción no como reconstruyó. Aquí restamos lo que sería la entrada original con la reconstrucción Aquí es donde está la diferencia que yo les decía, no estamos haciendo sumatoria, sino simplemente hacemos la diferencia Y esa manera. Él él predijo el precio de este carro deberían ser $10,000, pero el valor real que tiene son 5000 Entonces si coges 10,000.
Eh, Perdón 5000 - 10,000 Pues a traer el el valor negativo, por eso es que quiero que sea -1 en este caso que de hecho acabo de darme cuenta que de hecho esto está mal esto Debería ser así. Yo resto acá esto menos esto porque son los datos originales menos los datos reconstruidos, Sí así sería perdón, cuando ya tengo todo este esta matriz de reconstrucción es esto que está acá ejecutó Este modelo de Tim netbook, que era básicamente esto que acabamos de ver en pantalla, le digo vea, usted va a a entrenarse, básicamente con esta información es, eh, de enlace como el mapeo multidimensional de esas de todas las instancias y le digo, tráigame aquí en en el en el inicio cuando se construye acá le digo Tráeme los 10.
Que tengan pues esos datos a partir de este pib que le tiró y acá ya simplemente me entregaba esa información que es, eh, A partir de qué instancia entonces yo voy a utilizar este error de reconstrucción, eh? O Este modelo entrenado para encontrar a que sea más barato, pero que también tenga menos kilometraje que sea lo más pequeño que kilometraje o que la barra kilometraje cosas así en el en el vaina y bienes raíces suelo colocarle que sea barato y tras el hecho que sea grande en área, eso es lo que a veces se le pone Entonces esto ya me entrega los índices como los índices son como los ids, En esa lista grandota de cuáles son los que presentan esas anomalías y aquí es donde ya utilizo, Pues el dato original porque este dato se original básicamente es un espejo de este Data set ya preparado que tienen todas estas transformaciones, pero el original tiene como los datos, eh? De negocio, por eso la
Nos aparece como la que son los datos originales y ya eso es lo que él me entrega acá me entregaría como esa información, entonces le vamos a tirar a cada Candela para ver qué pasaría todo eso que Les acabo de comentar, eh? Y podemos ver al final este Data set que nos diría como Cuáles son las las que presentan esas condiciones ahorita incluso va a ser un poco confuso, pero vamos a hacer que funcione esto tiene aquí Espera que aquí la barre está era ejecutando otro Script Perdón voy a tirar este aquí, eh, Sí aquí en modo inferencia está ejecutando tres clip aquí arriba, Perdón chicos. Ya siguiente u listo vamos a ver esto que nos muestra que es el Data frame de las anomalías, entonces alquilamos tiempo listo y tenemos el dato.
Las anomalías bien está bastante chévere, si se dan cuenta son datos de negocio que sí, podemos entender podemos entender el modelo podemos entender el color que tienen al parecer los blancos con negro son los que están como descacha del precio, el que tiene el interior así, eh? Lgt Ese es el Stream no me acuerdo si era como el tipo algo así como que los datos ya o en el precio estos son los precios que deberían estar, eh? Mal ya ahorita vamos a ver cómo porque no se preguntaría bueno Esto me tiras eso, pero yo como sé en realidad. Sí, sí, esto es real, que ya lo vamos a ver Ya lo vamos a ver, pero con otro proyecto, pero ya vamos a ver cómo funciona. Entonces acá puedo ya encontrar esas anomalías deseados y me entrega la lista automáticamente con toda la información del negocio todos son de gasolina, al parecer son nuevas Pero me imagino que están en promoción, No lo sé nadie no está cruzado, eh? Quizás deberíamos leer un poco más.
Un concesionario en la promoción Habría que ver un poco cómo funciona eso todos son Volkswagen Bueno ahí hay que revisar hay que revisar ya un poco después los datos Pero esto debería haberse así esto es ya el resultado final pero lo vamos a ver con algo que yo he construido que quiero compartir con ustedes y aquí va la sorpresa porque se está interesado en comprar casa muchachos me me dicen y creo que les puedo dar una mano creo que les puedo ayudar a a conseguir una casa barata yo lastimosamente ya había comprado casa cuando termine esto pero cuando lo terminé Pues igual me pareció muy útil y estoy digamos lo estoy intentando sacarle provecho a nivel de negocio Pero lo que ven en pantalla son, eh? Propiedades que están en venta en Antioquia o específicamente en el valle de aburrá como pueden ver acá, eh? Que tienen ciertas condiciones.
Cómo se nos muestra nos muestra la dirección Este es el id que tiene la página web, si algo ahorita ya lo vemos cómo funciona la dirección exacta donde está la geolocalización tiene dos geolocalizaciones porque en el conjunto de datos se hace una preparación lo que a veces la geolocalización no es también desde la página web. Entonces utilice un servicio un servicio de Google Maps para poder mejorarlo Por eso tenemos dos geolocalizaciones acá listo, eh, Cuándo fue publicado. El el anuncio El espanto que tienen, por ejemplo acá se ve el estrato que es 5 3 6 hay varios el área que tienen, eh? Si es un apartamento o una casa el precio que tienen número de habitaciones Bueno hay más, eh? Precio de administración garajes sirve para mucho en realidad tiene mucha información Estas son las anomalías.
Esto sería básicamente la tabla que acabamos de ver de Carlos sí, pero si se dan cuenta en la parte inferior, hay más más hojas en este Excel cada una de esas hojas corresponde a los ites que aparecen en esta lista, sí Entonces vamos a echarle un vistazo a esas hojas, vamos a coger una al azar, que puede ser esto que creo que era un apartamento está en el apartado. Está se hizo el apartamento 450 millones. Está en Medellín en la Almería no sé dónde queda de hecho, pues no acaba de salir una una investigación sencilla rápida de Maps que nos diga dónde rayos estás tú ubicado. Entonces mira, nos dice que está por acá en esta parte de la ciudad de hecho está cerca donde yo vivo en realidad bien Vamos a abrir esa hoja, que es esta de acá está hoja que contiene.
Mete la misma información, pero la primera fila que aparece corresponde al apartamento que estamos evaluando es el, eh, calle i-85 80 87a 34 40 y los demás son los apartamentos que son más parecidos a ese apartamento que se utiliza el mismo truco que acabamos de ver ahorita key neighborhoods, pero ahí yo no le aplicó, eh? En realidad la instancia, eh? En ese caso es el mismo el mismo apartamento es decir, yo le estoy diciendo con ese keinet. Tráigame todos los apartamentos que sean muy parecidos a este apartamento Sí eso es lo que le estoy diciendo ahí. Tráigame todos los que sean muy parecidos que sean el estrato parecidos que estén muy parecidos en la geolocalización, eh? Tenga área para parecida y demás y si se dan cuenta Hay ciertos datos que son parecidos, por ejemplo, todos son apartamentos acá, se puede ver entonces un apartamentos en ese.
Este es el precio de hecho hay uno que parece que está bastante cerca A ver Mira ahorita miramos si hay diferencias que miren que si la Está chévere por ese lado estos son los precios ahí lo que está como en 1100,000 600 500 que son más o menos parecido en dimensiones y en la ubicación el área Este es el más grande y es el que tiene más habitaciones si se dan cuenta y quizás uno ya compararía la geolocalización y demás Pero incluso para este este problema que Aparentemente es más es sencillo, el modelo es capaz de encontrar esas diferencias entre como te digo esa tarea que podría ser un poco difícil de yo tener que ir a un barrio ver este apartamento Que Tiene ciertas, condiciones y intentar compararlo con otro que es más o menos parecido porque tiene una habitación de más o es ligeramente más grande y demás todo eso toda esa complejidad de ese trabajo te lo está simplificando el autor y te está.
En este caso Cuál es el más barato se dan cuenta, pues ganamos por dos lados. Es el más barato tiene una habitación de más tiene un área más grande, eh? Creo que es porque yo le dije que tuviera esas condiciones fuera más barato y tuviera un área grande. Creo que así como Se generó este almacén, eh? Viendo en pantalla y sí, la el área suele ser más pequeña y tras ello Pues a pesar de que el segundo es igual de precio, es más barato es lo que se ve allí, eh? Y pues pasa lo mismo con la mayoría. La mayoría vamos a encontrar que la fila la primera fila está más la más económica y el resto de condiciones suele ser muy parecidas de pronto para echarle un ojo a esta vamos a coger uno, que vamos a coger una dirección que esté acá vamos a coger esta abajo, mientras estás muy genérica. Quizás está. Te aparece acá. Abrimos paso otra vez la tiramos a ver qué tan lejos está esta ubicación. Bueno, acá sí está un poco lejos, quizás en en en estrato y
Te han parecidos porque creo que la otra era por aquí arriba, aunque esto también se puede ajustar. Yo le puedo decir que esté en un barrio específico o que la comparación que haga con con los demás inmuebles sea más cercana a geolocalización, eso también es posible hacerlo y que me encuentre el más el más barato varias condiciones, quizás este yo creo que está más cerca calle carrera 87, a ver, tiramos este acá. Sí, Mira este estaba cerca. Creo que el otro había quedado por aquí Arribita sí, pero así es ahí están aquí está banderita. Nos ayuda Eh es básicamente donde yo vivo y si está muy cerca geología en en geolocalización, está cerca Pero toda esta complejidad. Básicamente te la va a resumiría el autor para encontrar la oportunidad más barata y así así funciona con todos con las casas. Esta es una casa misma idea. Aquí están todas. Creo que bueno hay dos, en qué y demás Pero
Cómo funciona y así es como encuentras la anomalía el rarito deseado y ya es la idea, sería Cómo publicar semanalmente tal vez, eh? Inmuebles que estén, eh? Esa semana baratos y si alguno lo toma Única condición si lo toman me dicen para poder hacerle seguimiento y saber que funciona en el mundo real. Yo espero sacarle provecho en el mundo real pronto y comprar otro apartamento con este modelo y encontrar uno que sea barato que sea bueno, que sea chévere Cómo van dudas preguntas, todo bien, Todo bien, Laura de una dispara es que en el código habíamos hablado que sacaba las diferencias cierto y que por cada uno mira las diferencias y en el código Steven las partes que 00 y hay una parte que es -1 para mirar Cuál es el que está, pues más.
aparato que el resto Pero esto al final En qué parte la hace como ese cálculo de Pues que cero exactamente O sea la diferencia realmente sea cero O sea pues porque claro uno hace la diferencia Y puede que sea tienda acero Pero puede ser un poco más un poco menos Entonces esos números tan binarios, pues como De dónde salen no sé correcto la razón por la que yo me voy con cero y tú tienes toda la razón el error no siempre va a ser cero porque la reconstrucción va a tener un error siempre así sea mínimo pero a tener un error pero yo le estoy diciendo tráigame los que en estos en estos ejes, o sea en estas características reconstruí muy bien excepto en el precio si me entiendes por eso el punto el punto verde es nuestro referencia es nuestra instancia de referencia, le digo tráiganme los más cerca que tengan estas condiciones y de esa manera puedo detectar la anomalía pero la anomalía deseaba la anomalía con con lo que yo
por eso es que donde le dijiste que era la de referencia, o sea, esta parte tampoco la entiende en qué momento le dijiste no está la referencia y allá hagamos la invasión aquí entonces aquí yo inicié la referencia es este botón de ceros, por qué tiene un montón de ceros porque nosotros tuvimos que hacer toda esta transformación no, pero al final todas estas columnas representan el modelo del color para la plataforma todo esto sí excepto en el precio Esta no es referencia y ahora cuando yo inicializo el modelo de de clusterización Se podría decir de perdón, la utilización los Lucky en los más cercanos yo le digo vea primero usted va a traer los 10 más cercanos Este es un hiper parámetro que luce ellos me pregunta diga Cuántos necesita Cuántos más cercanos Necesita que le retorno le digo 10 20 30 40 los que yo quiera y él va a empezar aquí a a a funcionar así como yo te comentaba separa ahí y empieza a atrapar a los más cercanos y claro los que
Los que no Entre más lejos este este de esta referencia Pues no va a ser tan parecido a las condiciones que necesitamos entonces puede que ya empiece a presentar algunas anomalías, pero en otras cosas que a mí no me sirven ese tipo de cosas, Sí yo le estoy diciendo Dime más, por ejemplo, en el de los apartamentos Entonces él dice que sea el mismo barrio. Entonces hagamos. Un ejemplo que todos los de laureles que tengan cierto y que la única diferencia sea el precio, pero también va a haber otro que tenga todos los iguales todos los que sean en Belén entonces que tenga que sean todas las características iguales también va a sacar otro cluster, entonces ahí donde me queda, no me queda claro, es saca Cuántos cluster, o sea, porque claro, estamos diciéndole los 10 más cercanos, pero en cuánto van a ser los closer que va a sacar o algo así no sé no bien bien Está súper bien De hecho. Eso se puede manejar de diferentes maneras actualmente se manejas con un filtro previo, eh? Por ejemplo, si yo quiero que quede todas en Belén Entonces yo filtro, en ese Data set que le voy a enviar de entrada.
Filtro todos los que estén en Belén ellos ya sé que están en Belén Entonces cuando él reconstruye yo sé que todos los todas las opciones que me va a tirar va a ser en Belén y me va a encontrar el más barato, Sí o sea, es como filtro previo que puedes ir haciendo. Yo le digo Ah Pues todos los apartamentos que llegaron y se publicaron hoy, pero que estén en laureles Víctor todo lo de laureles, se lo paso y él me dice este es el más barato en laureles, en este momento Ah listo, listo, Gracias y ahí vas jugando ahí ya, ya funciona de hecho así como ya el bonus super bonus, eh? Así, se vería como ya desplegado el modelo Este es el modelo de de propiedades ya Full HD desplegado. Esto es muy parecido a lo que vimos con el precio de los carros misma idea se tiene un servicio con fase y voy a venir aquí Mientras tanto.
Eh, que nos que se está demorando tanto, vamos a ver Ahí está arrancando bien y le tiramos el servicio y esto ya básicamente sería el resultado de hecho de a partir de de este de este inferencia fue que yo construí esos archivos Excel que ustedes acaban de ver a partir ya del uso del modelo, que básicamente está aquí está haciendo lo mismo de siempre carga como todos los datos, eh? Aplica algunas transformaciones Aquí hay una diferencia pequeña, que es que todo el pre-proceso se hace cuando se inicializa el modelo porque eh, Cómo es la vaina Sí en la entrada. Yo no le estoy tirando, o sea, el funcionamiento aquí es diferente. Yo no le estoy diciendo en el servicio Ai Esta es este apartamento es una anomalía, no? Así no funciona que yo le tiraría la información del apartamento y él me entregaría como una un porcentaje de anomalía o algo así no funciona así el servicio sino que yo.
Diciendo Hey tráigame las cinco anomalías de esta semana Entonces toda esa información ya viene precargada Esa es la diferencia como en esta diferencia, entonces acá, por ejemplo, yo le estoy diciendo vea, tráigame los que están en Antioquia Me podría decir Bogotá porque yo también soy para Bogotá esto es discreto y no abrirlo por ahora. Esto es otra otra cosa, que yo estoy mejorando y yo le digo, tráigame los siete que sean anomalías y que tengan estas condiciones que el estrato sea, pues que sea bien. Que reconstruidas bien el precio sea tal, eh? Y que Ah me tienes que tipo de propiedad bien que el precio la embarré Sí y el resto que lo haga bien, pero también le podría decir y que el área la barre, pero positivamente que habrá Tráeme los más baratos, pero al tiempo los que son más más grandes eso es lo que le estoy diciendo ahí, eh, Y le digo tráigame los cinco más similares a esa propiedad que es la que acabamos de ver que esto es lo que podría hacerse también en los carros, pero tomaría un poco más de tiempo para uno decir.
Eso es una anomalía, pero con qué lo comparo Pues con esto es lo que hicimos en los excelentes lo comparas con esto y en los últimos 60 días o en los últimos 30 días o en los últimos 8 días en este caso lo tengo 60, porque está haciendo las pruebas. Lo voy a dejar así, por ejemplo por ahí es 25 Es que no sé si tengo datos hasta allá formatearse bien la base de datos y le puedes decir qué tipo de apartamento casa para construir futuramente puede ser fincas oficinas para allá va la cosa y se lo tiró Ay y tiro un error un poco de error Pero si son las demos no funciona a ver le tenemos 60 Ah es que sí es por el número de días. Ya les dije Jajaja siento Buenos días, es el número de días bien. Entonces acá ya tiene, me entrega como este Jason que tiene la información de la propiedad original, que es todo lo que acabamos de ver en el Excel esto es información ya de reconstruida, eh, Cuál es la información transformada y la reconstruida esto simplemente.
Términos técnicos por si se necesita Estos son dos apartamentos que son similares que es lo que acabamos de ver y me trae cinco uno dos tres cuatro cinco y luego salta otra vez al siguiente Ah bueno ya casi le incluye Incluso un precio predecido porque a este a este Data set Yo le hice Exactamente lo mismo que le hicimos a cast primero se hizo un modelo de predicción del precio de hecho, por ejemplo Creo que este precio hay que multiplicarlo por 1000 si no estoy mal para que nos entregue el precio real pero el precio que predice sería Este ahí lo acabo de copiar y veamos cuál es el precio que tiene entonces mira voy a copiarlo aquí en aquí va a abrir una nueva hoja Este es el precio que predice pero el el el el modelo de predicción no. Entonces el precio price, eh? Mode o algo así
Ya, y esto creo que se multiplica por 1000 Entonces le va a agregar tres ceros sería así de hecho mil o 10,000 100,000 no me acuerdo ahorita. Lo comparamos Es que creo que ahí fue, por fue algo muy parecido a lo que le hicimos en el de Cars vamos a copiar este price, hay algunas que son anomalías, por ejemplo este yo creo que es una anomalía que ya es como de pronto alguien metió mal el dedo, porque yo me imagino que esto no sé si es 120 Bueno tengo que mirar, quizás ese price Story también está funcionando muy bien, pero si comparamos con los demás, por ejemplo, este tiene 800 850 850 y este 830, pero posiblemente el área sea mayor el área del otro porque como le colocamos dos condiciones eso empieza a pasar.
Pues puede que yo fallé un poco más en el precio porque hay un similar que tiene un precio menor, pero si miramos el área, por ejemplo 420 El de acá miremos este que qué tal 4 Uf está fallando debería traer la anomalía. La otra lo tocaría mirar qué más tiene quizás en las otras condiciones es mejor el número de habitaciones o algo así Ah yo soy pendejo, perdón, Creo que estoy viendo el mismo Sí sí, sí, porque los similares son el primerito no es el mismo no dije nada, no dije nada. Ah, no sí, mientras estás pasando, no muchachos, me toca este caso me ha tocado, pero funciona a veces toca hacer estas variaciones manuales, pero si funciona si te tira Cuál es el más barato y ya bueno, la vemos, no sale también como esperaba de pronto por el precio voy a
En una página, eh Bueno aquí un poco dos cosas primero, entonces acá de finca raíz. Voy a hacer uno de estos con ustedes este eje que aparece acá es literalmente si me voy a aplicar raíz y pegó este anuncio, si es que todavía existe el anuncio porque son datos que puede que ya tengan cierta, vejez, finja raíz Entonces cuál es el problema, en qué raíz podría darse cuenta que cada las todas las semanas le estoy sacando información y podría hacerme la vida más difícil, entonces a veces en estos casos mantener un perfil bajo puede que sirva porque ahí va el número dos. Yo no soy dueño de los datos Inka raiz, indirectamente no sé Ah Mira así está aquí está la propiedad la casa en venta, entonces ahí va el problema después ellos pueden colocar.
Y Barreras y después me tocaba Modificar el código para sacar los datos de hecho, eso pasó en caps Carso ahorita no está funcionando el scrappy, porque cambiaron la forma en la que se sacaba los detalles no he tenido tiempo de arreglar ahí. Sí, ahí no sé si ya respondí tu pregunta, sí, sí, sí, sí, sí es una vaina compleja el hecho de quitar datos de la web. Toca hacerlo con mañanita Entonces por ahora perfil bajo por ahora hagamos que funcione, pero ahora le sacó provecho personal y quizás en serio, lo va a publicar, va a haber un canal todas las personas que estén al grupo de estudio, pues van a tener acceso a ese calor, semanalmente publicando hoy esta semana salió este apartamento nuevo entonces La Única condición si lo llegan a comprar, me dicen porque de esa manera sé que funcionó.
No, solamente teóricamente sino en el mundo real la plata la plata Okay podemos hacer sociedad si está inversión, pues es más fácil, si ya sabes cuál es el barato, digamos Sí yo también lo he pensado. Creo que en serio hay muchas oportunidades semanalmente o mensualmente eran unas siete buenas siete ocho tal vez 10 y pues no me da para comprar 10 casas, así que mejor, pues si alguien puede pues que la use Solo que me diga, por eso se funcione y ya chicos. Eso era todo por ahora les voy a compartir el reporta, un momento la grabación también y próxima semana vemos la rack Julián nos va a apoyar súper bien y próximo proyecto.
Eso Julia Gracias y próximo proyecto indeciso, eh? La verdad me gusta abrir la puerta, he pensado en renforcement learning, he pensado en modelos, no supervisados, he pensado incluso cuando la otra lm también, okay, creo que ahorita está muy bombeado, pues seguro que habrán muchos cursos por ahí del tema y vamos a ver eso en la rack Pero entonces va a estar ahí la puerta abierta Quizás vamos a hacer un pool otra vez una votación están estos temas quizás estos proyectos y que nos lanzamos construimos algo chévere otra vez desde cero y lo vendemos, le sacamos provecho esta vez listo chicos, no sé si tienen dudas o ya nos veríamos dentro de ocho César Muchas gracias, Ale Sí señor. Sí, señor, Dale chicos, Muchas gracias, Nos vemos hasta la
 próxima Cuídense buenas noches